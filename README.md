# ğŸ›©ï¸ DÃ©tection de Contrails par Deep Learning

> Projet de classification binaire utilisant PyTorch et Transfer Learning pour dÃ©tecter automatiquement les contrails (traÃ®nÃ©es de condensation) dans des images satellites.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [RÃ©sultats](#-rÃ©sultats)
- [Structure du Projet](#-structure-du-projet)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me de dÃ©tection automatique de contrails dans des images satellites en utilisant des techniques de Deep Learning avancÃ©es. Les contrails (condensation trails) sont des traÃ®nÃ©es de condensation laissÃ©es par les avions et leur dÃ©tection automatique est importante pour :

- **Ã‰tudes climatologiques** : Impact des contrails sur le climat
- **Surveillance aÃ©rienne** : DÃ©tection automatique dans les images satellites
- **Recherche aÃ©ronautique** : Analyse de l'impact environnemental du trafic aÃ©rien

### Objectif

CrÃ©er un modÃ¨le de classification binaire capable de dÃ©terminer si une image satellite contient des contrails ou non :
- **Classe 0** : Pas de contrail dans l'image
- **Classe 1** : Contrails prÃ©sents dans l'image

---

## âœ¨ FonctionnalitÃ©s

### ğŸ”¬ FonctionnalitÃ©s Principales

- âœ… **Classification binaire** avec ResNet50 et Transfer Learning
- âœ… **Visualisation Grad-CAM** : Zones d'attention du modÃ¨le
- âœ… **Analyse approfondie** : Matrice de confusion, mÃ©triques dÃ©taillÃ©es
- âœ… **Analyse des erreurs** : Faux positifs/nÃ©gatifs avec visualisations
- âœ… **Distribution des probabilitÃ©s** : Analyse de confiance du modÃ¨le
- âœ… **Pipeline complet** : De la prÃ©paration des donnÃ©es Ã  l'Ã©valuation

### ğŸ“Š MÃ©triques Ã‰valuÃ©es

- **Accuracy** : PrÃ©cision globale
- **Precision** : PrÃ©cision des prÃ©dictions positives
- **Recall** : Taux de dÃ©tection des vrais positifs
- **F1-Score** : Moyenne harmonique de Precision et Recall
- **Matrice de confusion** : Analyse dÃ©taillÃ©e des erreurs

---

## ğŸ—ï¸ Architecture

### ModÃ¨le

- **Architecture de base** : ResNet50 prÃ©-entraÃ®nÃ© sur ImageNet
- **Transfer Learning** : Adaptation de la derniÃ¨re couche pour classification binaire
- **Fine-tuning** : Ajustement des poids sur le dataset de contrails

### Pipeline de DonnÃ©es

```
Images PNG â†’ Preprocessing â†’ Augmentation â†’ Normalisation â†’ ResNet50 â†’ Classification
```

### Techniques UtilisÃ©es

- **Data Augmentation** : Flip horizontal, rotation, ajustement couleur
- **Normalisation** : Statistiques ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
- **Optimization** : Adam optimizer avec learning rate 0.001
- **Loss Function** : CrossEntropyLoss

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- PyTorch 2.0+
- CUDA (optionnel, pour GPU)

### Installation des DÃ©pendances

```bash
pip install torch torchvision
pip install numpy pillow matplotlib
pip install scikit-learn seaborn
```

### Structure du Dataset

Organisez vos donnÃ©es comme suit :

```
SingleFrame_PNG/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/          # Images PNG/JPG
â”‚   â””â”€â”€ ground_truth/     # Labels .npy
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ ground_truth/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ ground_truth/
```

---

## ğŸ’» Utilisation

### 1. Configuration

Ouvrez le notebook `atmo_class.ipynb` et ajustez le chemin du dataset :

```python
DATA_DIR = 'SingleFrame_PNG'  # Votre chemin
BATCH_SIZE = 32
IMAGE_SIZE = 224
NUM_EPOCHS = 10
LEARNING_RATE = 0.001
```

### 2. ExÃ©cution

ExÃ©cutez les cellules du notebook dans l'ordre :

1. **Imports et configuration**
2. **Dataset et DataLoader**
3. **PrÃ©paration des donnÃ©es**
4. **ModÃ¨le ResNet50**
5. **EntraÃ®nement**
6. **Ã‰valuation**
7. **Grad-CAM et visualisations**
8. **Analyse des erreurs**

### 3. Charger un ModÃ¨le SauvegardÃ©

```python
checkpoint = torch.load('contrails_classifier_resnet50.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# Faire une prÃ©diction
model.eval()
with torch.no_grad():
    output = model(image_tensor)
    prediction = torch.argmax(output, dim=1)
    probability = torch.softmax(output, dim=1)
```

---

## ğŸ“ˆ RÃ©sultats

### MÃ©triques Typiques

Sur un dataset Ã©quilibrÃ©, le modÃ¨le atteint gÃ©nÃ©ralement :

- **Accuracy** : > 85%
- **F1-Score** : > 0.80
- **Precision** : > 0.82
- **Recall** : > 0.78

*Note : Les rÃ©sultats varient selon la qualitÃ© et la taille du dataset.*

### Visualisations

Le notebook gÃ©nÃ¨re automatiquement :

1. **Courbes d'apprentissage** : Ã‰volution de la loss et accuracy
2. **Grad-CAM heatmaps** : Zones d'attention du modÃ¨le
3. **Matrice de confusion** : Analyse des erreurs
4. **Distribution des probabilitÃ©s** : Confiance du modÃ¨le
5. **Exemples d'erreurs** : Faux positifs/nÃ©gatifs avec explications

---

## ğŸ“ Structure du Projet

```
atmo/
â”œâ”€â”€ atmo_class.ipynb          # Notebook principal
â”œâ”€â”€ README.md                 # Ce fichier
â”œâ”€â”€ PROJECT_EXPLANATION.md    # Explication dÃ©taillÃ©e du projet
â”œâ”€â”€ INTERNSHIP_EVALUATION.md # Ã‰valuation pour stage
â””â”€â”€ contrails_classifier_resnet50.pth  # ModÃ¨le sauvegardÃ© (gÃ©nÃ©rÃ©)
```

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **PyTorch** : Framework de Deep Learning
- **Torchvision** : ModÃ¨les prÃ©-entraÃ®nÃ©s et transformations
- **NumPy** : Calculs numÃ©riques
- **PIL/Pillow** : Traitement d'images
- **Matplotlib** : Visualisations
- **Seaborn** : Visualisations statistiques
- **Scikit-learn** : MÃ©triques d'Ã©valuation

---

## ğŸ“ Points Techniques ClÃ©s

### Transfer Learning

Le modÃ¨le utilise ResNet50 prÃ©-entraÃ®nÃ© sur ImageNet, ce qui permet :
- **Apprentissage rapide** : Moins d'Ã©poques nÃ©cessaires
- **Meilleures performances** : Avec moins de donnÃ©es
- **GÃ©nÃ©ralisation** : Patterns visuels dÃ©jÃ  appris

### Grad-CAM

ImplÃ©mentation de Gradient-weighted Class Activation Mapping pour :
- **InterprÃ©tabilitÃ©** : Comprendre oÃ¹ le modÃ¨le regarde
- **Validation** : VÃ©rifier que le modÃ¨le se concentre sur les bonnes rÃ©gions
- **Debugging** : Identifier les biais potentiels

### Analyse des Erreurs

Analyse approfondie pour :
- **Comprendre les limites** du modÃ¨le
- **Identifier les cas difficiles**
- **Guider les amÃ©liorations futures**

---

## ğŸ”® AmÃ©liorations Futures

- [ ] **Segmentation U-Net** : Localisation prÃ©cise des contrails
- [ ] **Ensemble de modÃ¨les** : Combinaison de plusieurs architectures
- [ ] **Fine-tuning avancÃ©** : Learning rate scheduling, early stopping
- [ ] **Augmentation avancÃ©e** : Mixup, CutMix
- [ ] **Architectures alternatives** : EfficientNet, Vision Transformer

---

## ğŸ“ Auteur

Projet dÃ©veloppÃ© dans le cadre d'une candidature pour un stage de recherche.

---

## ğŸ“„ License

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- **ONERA** pour le contexte d'application
- **PyTorch Team** pour le framework
- **ImageNet** pour les poids prÃ©-entraÃ®nÃ©s

---

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue.

---

**â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  le star sur GitHub !**

